

# ComputerVisionProject

Complete pipeline for multi-camera 3D reconstruction of moving objects using YOLO, tracking, interpolation, triangulation, and visualization.

## Description
This project allows you to:
- Run YOLO inference on multi-camera videos
- Perform 2D tracking and temporal interpolation of detections
- Triangulate 3D points from multiple views
- Evaluate performance against ground truth
- Visualize results in 3D

## Requirements
- Python 3.8+
- [Ultralytics YOLOv8](https://docs.ultralytics.com/) (`pip install ultralytics`)
- OpenCV, NumPy, Matplotlib, PyYAML, torch
- Recommended: Conda environment

## Installation
1. Clone the repository and move into the project folder.
2. Install dependencies:
	```bash
	conda create -n cv python=3.10
	conda activate cv
	pip install -r requirements.txt
	# or install manually: ultralytics opencv-python numpy matplotlib pyyaml torch
	```

## Main Folder Structure
- `dataset/` : images, YOLO labels, videos, split into train/val/test
- `camparams/` : camera calibration files
- `weights/` : pre-trained and fine-tuned YOLO models
- `runs/` : inference, tracking, triangulation, evaluation results

## Main Pipeline
The complete pipeline is managed by `pipeline.py` and can be configured via `run.sh` or CLI.

### Typical Flow:
1. YOLO inference on multi-camera videos (`--infer-videos`)
2. 2D tracking and interpolation (optional)
3. Optical distortion rectification (optional)
4. Multi-camera 3D triangulation
5. Evaluation against ground truth (optional)
6. Interactive 3D visualization (optional)

## How to Run the Pipeline

### Full execution (from PowerShell or bash):
```bash
sh run.sh
# or manually:
python pipeline.py --infer-videos --interpolate --rectify --evaluate-labels --visualize --device 0
```

### Main options (`pipeline.py`):
- `--cameras 2 4 13` : camera IDs to process
- `--labels-dir dataset/infer_video` : labels directory
- `--infer-videos` : run YOLO inference on videos
- `--interpolate` : enable detection interpolation
- `--rectify` : correct optical distortions
- `--evaluate-labels` : evaluate IoU against ground truth
- `--visualize` : visualize 3D results
- `--model weights/fine_tuned_yolo_final.pt` : YOLO model to use
- `--device 0` : GPU/CPU

For all options see `config.py` or the help of `pipeline.py`.

## Custom YOLO Training
To train/fine-tune YOLO on a custom dataset:
```bash
python fine_tune.py
# Edit parameters/dataset in fine_tune.py if needed
```
The trained model will be saved in `weights/`.

## Evaluation
To evaluate YOLO model performance on a test dataset:
```bash
python evaluation.py --model weights/fine_tuned_yolo_final.pt --images dataset/test/images --labels dataset/test/labels --device 0
```
Output: IoU metrics per image and class, final average.

## 3D Triangulation and Visualization
To triangulate 3D points from YOLO labels:
```bash
python triangulation_3d.py
```
To visualize 3D points:
```bash
python visualizer_3d.py
```

## Dataset
The expected structure is in `dataset/`:
- `train/`, `val/`, `test/` with subfolders `images/` and `labels/` (YOLO format)
- `video/` for original videos
- `infer_video/` for labels generated by inference

## Credits
Developed by [your name/team].
Based on Ultralytics YOLOv8.

## License
MIT License